import sys
import subprocess
import os

sys.stdout.reconfigure(encoding="utf-8")

def install_package(package):
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏û‡πá‡∏Å‡πÄ‡∏Å‡∏à‡∏ú‡πà‡∏≤‡∏ô pip"""
    print(f"üîß ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á {package} ...")
    try:
        subprocess.check_call([sys.executable, "-m", "pip", "install", package])
        print(f"‚úÖ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á {package} ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
    except Exception as e:
        print(f"‚ùå ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á {package} ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")

print("‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö...")

required_libs = [
    ("langchain", "langchain.chains"),
    ("langchain-community", "langchain_community"),
    ("langchain-text-splitters", "langchain_text_splitters"),
    ("chromadb", "chromadb"),
]

for package_name, import_name in required_libs:
    try:
        __import__(import_name)
    except ImportError:
        print(f"‚ö†Ô∏è ‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏ß‡πà‡∏≤‡∏Ç‡∏≤‡∏î‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°: {package_name}")
        install_package(package_name)

try:
    from langchain_community.llms import Ollama
    from langchain_community.embeddings import OllamaEmbeddings
    from langchain_community.document_loaders import TextLoader
    from langchain_community.vectorstores import Chroma
    from langchain.chains import RetrievalQA
    from langchain.prompts import PromptTemplate
    from langchain_text_splitters import CharacterTextSplitter
except ImportError as e:
    print("\n‚ùå Import ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß")
    print(f"Error: {e}")
    sys.exit()

print("\nü§ñ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏™‡∏°‡∏≠‡∏á AI (Llama3)...")
llm = Ollama(model="llama3")
embeddings = OllamaEmbeddings(model="nomic-embed-text")

print("üìÇ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏¢‡∏≤...")
data_path = "./data/clean_knowledge.txt"

if not os.path.exists(data_path):
    print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå: {data_path}")
    sys.exit()

loader = TextLoader(data_path, encoding="utf-8")
documents = loader.load()

text_splitter = CharacterTextSplitter(chunk_size=800, chunk_overlap=100)
texts = text_splitter.split_documents(documents)
print(f"üìä ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô chunk ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(texts)}")

CHROMA_DIR = "./chroma_db"

if os.path.exists(CHROMA_DIR):
    print("‚ö° ‡πÇ‡∏´‡∏•‡∏î Vector DB ‡πÄ‡∏î‡∏¥‡∏°...")
    db = Chroma(
        persist_directory=CHROMA_DIR,
        embedding_function=embeddings
    )
else:
    print("‚öôÔ∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Vector DB ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å (‡∏≠‡∏≤‡∏à‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏´‡∏•‡∏≤‡∏¢‡∏ô‡∏≤‡∏ó‡∏µ)...")
    db = Chroma.from_documents(
        texts,
        embeddings,
        persist_directory=CHROMA_DIR
    )
    db.persist()
    print("‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á Vector DB ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")

retriever = db.as_retriever(search_type="similarity", search_kwargs={"k": 3})

prompt_template = """
‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ AI Health Buddy ‡πÄ‡∏†‡∏™‡∏±‡∏ä‡∏Å‡∏£‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞
‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏¢‡∏≤‡∏à‡∏≤‡∏Å Context ‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏¢‡∏≤:
{context}

‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {question}

‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ (‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):
1. ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡∏¢‡∏≤‡∏ó‡∏µ‡πà "‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏≠‡∏≤‡∏Å‡∏≤‡∏£" ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ñ‡∏≤‡∏°
2. ‡∏ö‡∏≠‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡∏¢‡∏≤, ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏£‡∏á, ‡πÅ‡∏•‡∏∞‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏¢‡∏≤
3. ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏¢‡∏≤‡∏≠‡∏±‡∏ô‡∏ï‡∏£‡∏≤‡∏¢ (Prescription) ‡πÉ‡∏´‡πâ‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏ß‡πà‡∏≤ "‡∏¢‡∏≤‡∏≠‡∏±‡∏ô‡∏ï‡∏£‡∏≤‡∏¢ ‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡πÅ‡∏û‡∏ó‡∏¢‡πå/‡πÄ‡∏†‡∏™‡∏±‡∏ä‡∏Å‡∏£‡∏Å‡πà‡∏≠‡∏ô‡∏ã‡∏∑‡πâ‡∏≠"
4. ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏¢‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏≠‡∏≤‡∏Å‡∏≤‡∏£ ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏ß‡πà‡∏≤ "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏¢‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏ô‡∏µ‡πâ‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏£‡∏±‡∏ö"

‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:
"""

PROMPT = PromptTemplate(
    template=prompt_template,
    input_variables=["context", "question"]
)

qa = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=retriever,
    chain_type_kwargs={"prompt": PROMPT}
)

# ---------------- Loop ----------------
print("\n‚úÖ AI Health Buddy ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡πâ‡∏ß! (‡∏û‡∏¥‡∏°‡∏û‡πå 'exit' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å)")
print("---------------------------------------------------")

while True:
    query = input("\n‡∏ö‡∏≠‡∏Å‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏°‡∏≤‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢: ")
    if query.lower() == "exit":
        break

    print("ü§ñ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå...")
    try:
        result = qa.invoke(query)
        print(f"‡πÄ‡∏†‡∏™‡∏±‡∏ä‡∏Å‡∏£ AI: {result['result']}")
    except Exception as e:
        print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
